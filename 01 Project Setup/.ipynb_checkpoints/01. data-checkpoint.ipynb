{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e9978fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import datasets\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "203d9542",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataModule(pl.LightningDataModule):\n",
    "    def __init__(self, model_name=\"google/bert_uncased_L-2_H-128_A-2\", batch_size=32):\n",
    "        super().__init__()\n",
    "\n",
    "        self.batch_size = batch_size\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "    def prepare_data(self):\n",
    "        cola_dataset = load_dataset(\"glue\", \"cola\")\n",
    "        self.train_data = cola_dataset[\"train\"]\n",
    "        self.val_data = cola_dataset[\"validation\"]\n",
    "\n",
    "    def tokenize_data(self, example):\n",
    "        return self.tokenizer(\n",
    "            example[\"sentence\"],\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",\n",
    "            max_length=512,\n",
    "        )\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        # we set up only relevant datasets when stage is specified\n",
    "        if stage == \"fit\" or stage is None:\n",
    "            self.train_data = self.train_data.map(self.tokenize_data, batched=True)\n",
    "            self.train_data.set_format(\n",
    "                type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"]\n",
    "            )\n",
    "\n",
    "            self.val_data = self.val_data.map(self.tokenize_data, batched=True)\n",
    "            self.val_data.set_format(\n",
    "                type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"]\n",
    "            )\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return torch.utils.data.DataLoader(\n",
    "            self.train_data, batch_size=self.batch_size, shuffle=True\n",
    "        )\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return torch.utils.data.DataLoader(\n",
    "            self.val_data, batch_size=self.batch_size, shuffle=False\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f814790",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset glue (C:\\Users\\bhatt\\.cache\\huggingface\\datasets\\glue\\cola\\1.0.0\\dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n",
      "Parameter 'function'=<bound method DataModule.tokenize_data of <__main__.DataModule object at 0x000001A799E25730>> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9adc234a695f4610843bf2c783e97c51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=9.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6044725a9e72488da8157c87186c1bb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "torch.Size([32, 512])\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    data_model = DataModule()\n",
    "    data_model.prepare_data()\n",
    "    data_model.setup()\n",
    "    print(next(iter(data_model.train_dataloader()))[\"input_ids\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dbc51f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
